{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe02da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "from model import UNet, DoubleConv\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "from utils import (\n",
    "    DiceBCELoss,\n",
    "    train_epoch,\n",
    "    validate_epoch,\n",
    "    EarlyStopping\n",
    ")\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c192014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\\n\n",
    "# CONFIGURATION (Updated for Task 2)\n",
    "# ============================================================================\\n\n",
    "train_file = 'train.txt'\n",
    "val_file = 'val.txt'\n",
    "\n",
    "class Config:\n",
    "    # Dataset paths\n",
    "    DATASET_PATH = \"data\\\\kvasir-seg\"\n",
    "    IMAGE_DIR = \"images\"\n",
    "    MASK_DIR = \"masks\"\n",
    "    \n",
    "    # Experiment parameters\n",
    "    # RESOLUTIONS = [512, 256, 128, 64] # <-- Removed/Commented out (Task 1 only)\n",
    "    TARGET_SIZE = 256\n",
    "    \n",
    "    # Training parameters\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_EPOCHS = 25\n",
    "    LEARNING_RATE = 1e-4\n",
    "    \n",
    "    # Early stopping\n",
    "    EARLY_STOPPING_PATIENCE = 5 \n",
    "    # LR Scheduler\n",
    "    SCHEDULER_PATIENCE = 3 \n",
    "    SCHEDULER_FACTOR = 0.1 \n",
    "    \n",
    "    # Model parameters\n",
    "    IN_CHANNELS = 3\n",
    "    OUT_CHANNELS = 1\n",
    "    FEATURES = [64, 128, 256, 512]\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# AUGMENTATION_TYPE = \"hflip\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4f805a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KvasirDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, target_size=256, augmentation_type=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        \n",
    "        # Base transforms (always applied)\n",
    "        base_transforms = [\n",
    "            A.Resize(height=target_size, width=target_size, interpolation=cv2.INTER_LINEAR),\n",
    "        ]\n",
    "        \n",
    "        # Add augmentation based on type\n",
    "        if augmentation_type == 'hflip':\n",
    "            aug_transforms = [A.HorizontalFlip(p=0.5)]\n",
    "        elif augmentation_type == 'vflip':\n",
    "            aug_transforms = [A.VerticalFlip(p=0.5)]\n",
    "        elif augmentation_type == 'rotate':\n",
    "            aug_transforms = [A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, \n",
    "                                      border_mode=cv2.BORDER_REFLECT_101, p=0.7)]\n",
    "        elif augmentation_type == 'colorjitter':\n",
    "            aug_transforms = [A.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                                           saturation=0.2, hue=0.1, p=0.7)]\n",
    "        elif augmentation_type == 'all':\n",
    "            aug_transforms = [\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, \n",
    "                        border_mode=cv2.BORDER_REFLECT101, p=0.7),\n",
    "                A.OneOf([\n",
    "                    A.GaussianBlur(blur_limit=(3, 5), p=0.5),\n",
    "                    A.ColorJitter(brightness=0.2, contrast=0.2, \n",
    "                             saturation=0.2, hue=0.1, p=0.7)\n",
    "                ],p=0.07)\n",
    "            ]\n",
    "        else:\n",
    "            aug_transforms = []\n",
    "        \n",
    "        # Final transforms (always applied)\n",
    "        final_transforms = [\n",
    "            A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
    "            ToTensorV2()\n",
    "        ]\n",
    "        \n",
    "        # Combine all transforms\n",
    "        self.transform = A.Compose(base_transforms + aug_transforms + final_transforms)\n",
    "\n",
    "    def __len__(self):  # <-- MAKE SURE YOU HAVE THIS!\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):  # <-- AND THIS!\n",
    "        # Load image and mask with cv2\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Binarize mask (0 or 1)\n",
    "        mask = (mask > 128).astype(np.uint8)\n",
    "        \n",
    "        # Apply transforms\n",
    "        augmented = self.transform(image=image, mask=mask)\n",
    "        \n",
    "        image_tensor = augmented['image']\n",
    "        mask_tensor = augmented['mask']\n",
    "        \n",
    "        # Add channel dimension to mask (H, W) -> (1, H, W)\n",
    "        mask_tensor = mask_tensor.unsqueeze(0).float()\n",
    "        \n",
    "        return image_tensor, mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d58a0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 700 images, Val: 300 images\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PATH COLLECTION AND VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Simple file existence check\n",
    "if not os.path.exists('train.txt') or not os.path.exists('val.txt'):\n",
    "    raise FileNotFoundError('train.txt or val.txt missing.')\n",
    "\n",
    "base_path = Path(config.DATASET_PATH)\n",
    "image_paths = sorted(list((base_path / config.IMAGE_DIR).glob('*.jpg')))\n",
    "mask_paths = sorted(list((base_path / config.MASK_DIR).glob('*.jpg')))\n",
    "\n",
    "if len(image_paths) != len(mask_paths):\n",
    "    raise ValueError(\"Mismatch between number of images and masks.\")\n",
    "\n",
    "# Read train/val lists\n",
    "with open('train.txt', 'r') as f:\n",
    "    train_stems = {line.strip() for line in f}\n",
    "with open('val.txt', 'r') as f:\n",
    "    val_stems = {line.strip() for line in f}\n",
    "\n",
    "# Split dataset according to txt files\n",
    "train_images = [p for p in image_paths if p.stem in train_stems]\n",
    "train_masks = [p for p in mask_paths if p.stem in train_stems]\n",
    "val_images = [p for p in image_paths if p.stem in val_stems]\n",
    "val_masks = [p for p in mask_paths if p.stem in val_stems]\n",
    "\n",
    "print(f\"Train: {len(train_images)} images, Val: {len(val_images)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0814aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n",
      "Input shape: torch.Size([1, 3, 256, 256])\n",
      "Output shape: torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL CALL\n",
    "# ============================================================================\n",
    "\n",
    "def test_model_call():\n",
    "    model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "    print(\"Model created successfully!\")\n",
    "    \n",
    "    # Create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "test_model_call()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728094d8",
   "metadata": {},
   "source": [
    "# Load dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7e8adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images\n",
      "Training:   700 images (70.0%)\n",
      "Validation: 300 images (30.0%)\n"
     ]
    }
   ],
   "source": [
    "# Check files exist\n",
    "if not os.path.exists('train.txt') or not os.path.exists('val.txt'):\n",
    "    raise FileNotFoundError('train.txt or val.txt missing!')\n",
    "\n",
    "# Get all image and mask paths\n",
    "base_path = Path(config.DATASET_PATH)\n",
    "image_paths = sorted(list((base_path / config.IMAGE_DIR).glob('*.jpg')))\n",
    "mask_paths = sorted(list((base_path / config.MASK_DIR).glob('*.jpg')))\n",
    "\n",
    "if len(image_paths) != len(mask_paths):\n",
    "    raise ValueError(\"Mismatch between images and masks!\")\n",
    "\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "# Read train/val split\n",
    "with open('train.txt', 'r') as f:\n",
    "    train_stems = {line.strip() for line in f}\n",
    "with open('val.txt', 'r') as f:\n",
    "    val_stems = {line.strip() for line in f}\n",
    "\n",
    "# Split dataset\n",
    "train_images = [p for p in image_paths if p.stem in train_stems]\n",
    "train_masks = [p for p in mask_paths if p.stem in train_stems]\n",
    "val_images = [p for p in image_paths if p.stem in val_stems]\n",
    "val_masks = [p for p in mask_paths if p.stem in val_stems]\n",
    "\n",
    "# Print split info\n",
    "print(f\"Training:   {len(train_images)} images ({len(train_images)/(len(train_images)+len(val_images))*100:.1f}%)\")\n",
    "print(f\"Validation: {len(val_images)} images ({len(val_images)/(len(train_images)+len(val_images))*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f4f42",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b6dcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating datasets...\n",
      "Training batches: 88\n",
      "Validation batches: 38\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating datasets...\")\n",
    "\n",
    "# Training dataset WITH AUGMENTATION\n",
    "train_dataset = KvasirDataset(\n",
    "    train_images, \n",
    "    train_masks, \n",
    "    target_size=config.TARGET_SIZE,\n",
    "    augmentation_type = AUGMENTATION_TYPE\n",
    ")\n",
    "\n",
    "# Validation dataset WITHOUT AUGMENTATION\n",
    "val_dataset = KvasirDataset(\n",
    "    val_images, \n",
    "    val_masks, \n",
    "    target_size=config.TARGET_SIZE,\n",
    "    augmentation_type = None\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa13099",
   "metadata": {},
   "source": [
    "# MAIN TRAINING LOOP (WITH LR SCHEDULING + EARLY STOPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f1549aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STARTING EXPERIMENT FOR AUGMENTATION: BASELINE\n",
      "==================================================\n",
      "Epoch 1/25.. Train Loss: 0.5302.. Val Loss: 0.5256.. Val Dice: 0.5567.. Val IoU: 0.3897\n",
      "Validation loss decreased (0.5567). Saving model...\n",
      "Epoch 2/25.. Train Loss: 0.4523.. Val Loss: 0.4312.. Val Dice: 0.6146.. Val IoU: 0.4487\n",
      "Validation loss decreased (0.6146). Saving model...\n",
      "Epoch 3/25.. Train Loss: 0.4159.. Val Loss: 0.6078.. Val Dice: 0.5377.. Val IoU: 0.3723\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 4/25.. Train Loss: 0.3837.. Val Loss: 0.3936.. Val Dice: 0.6310.. Val IoU: 0.4676\n",
      "Validation loss decreased (0.6310). Saving model...\n",
      "Epoch 5/25.. Train Loss: 0.3606.. Val Loss: 0.3619.. Val Dice: 0.6561.. Val IoU: 0.4966\n",
      "Validation loss decreased (0.6561). Saving model...\n",
      "Epoch 6/25.. Train Loss: 0.3279.. Val Loss: 0.3271.. Val Dice: 0.6883.. Val IoU: 0.5339\n",
      "Validation loss decreased (0.6883). Saving model...\n",
      "Epoch 7/25.. Train Loss: 0.3022.. Val Loss: 0.3208.. Val Dice: 0.6931.. Val IoU: 0.5377\n",
      "Validation loss decreased (0.6931). Saving model...\n",
      "Epoch 8/25.. Train Loss: 0.2833.. Val Loss: 0.3009.. Val Dice: 0.7152.. Val IoU: 0.5641\n",
      "Validation loss decreased (0.7152). Saving model...\n",
      "Epoch 9/25.. Train Loss: 0.2537.. Val Loss: 0.3013.. Val Dice: 0.7049.. Val IoU: 0.5545\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 10/25.. Train Loss: 0.2433.. Val Loss: 0.3053.. Val Dice: 0.7073.. Val IoU: 0.5585\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 11/25.. Train Loss: 0.2237.. Val Loss: 0.2956.. Val Dice: 0.7259.. Val IoU: 0.5753\n",
      "Validation loss decreased (0.7259). Saving model...\n",
      "Epoch 12/25.. Train Loss: 0.2021.. Val Loss: 0.2649.. Val Dice: 0.7426.. Val IoU: 0.6007\n",
      "Validation loss decreased (0.7426). Saving model...\n",
      "Epoch 13/25.. Train Loss: 0.1970.. Val Loss: 0.2718.. Val Dice: 0.7383.. Val IoU: 0.5945\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 14/25.. Train Loss: 0.1719.. Val Loss: 0.2521.. Val Dice: 0.7685.. Val IoU: 0.6303\n",
      "Validation loss decreased (0.7685). Saving model...\n",
      "Epoch 15/25.. Train Loss: 0.1691.. Val Loss: 0.2685.. Val Dice: 0.7407.. Val IoU: 0.6002\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 16/25.. Train Loss: 0.1571.. Val Loss: 0.2614.. Val Dice: 0.7522.. Val IoU: 0.6141\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 17/25.. Train Loss: 0.1411.. Val Loss: 0.2962.. Val Dice: 0.7197.. Val IoU: 0.5791\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 18/25.. Train Loss: 0.1304.. Val Loss: 0.2573.. Val Dice: 0.7560.. Val IoU: 0.6178\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 19/25.. Train Loss: 0.1076.. Val Loss: 0.2404.. Val Dice: 0.7735.. Val IoU: 0.6440\n",
      "Validation loss decreased (0.7735). Saving model...\n",
      "Epoch 20/25.. Train Loss: 0.0929.. Val Loss: 0.2331.. Val Dice: 0.7829.. Val IoU: 0.6554\n",
      "Validation loss decreased (0.7829). Saving model...\n",
      "Epoch 21/25.. Train Loss: 0.0885.. Val Loss: 0.2319.. Val Dice: 0.7862.. Val IoU: 0.6593\n",
      "Validation loss decreased (0.7862). Saving model...\n",
      "Epoch 22/25.. Train Loss: 0.0862.. Val Loss: 0.2358.. Val Dice: 0.7817.. Val IoU: 0.6545\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 23/25.. Train Loss: 0.0819.. Val Loss: 0.2336.. Val Dice: 0.7850.. Val IoU: 0.6575\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 24/25.. Train Loss: 0.0803.. Val Loss: 0.2379.. Val Dice: 0.7805.. Val IoU: 0.6522\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 25/25.. Train Loss: 0.0781.. Val Loss: 0.2348.. Val Dice: 0.7846.. Val IoU: 0.6578\n",
      "EarlyStopping counter: 4 out of 5\n",
      "==================================================\n",
      "STARTING EXPERIMENT FOR AUGMENTATION: HFLIP\n",
      "==================================================\n",
      "Epoch 1/25.. Train Loss: 0.5773.. Val Loss: 0.4991.. Val Dice: 0.5261.. Val IoU: 0.3618\n",
      "Validation loss decreased (0.5261). Saving model...\n",
      "Epoch 2/25.. Train Loss: 0.4941.. Val Loss: 0.4741.. Val Dice: 0.5364.. Val IoU: 0.3729\n",
      "Validation loss decreased (0.5364). Saving model...\n",
      "Epoch 3/25.. Train Loss: 0.4590.. Val Loss: 0.4418.. Val Dice: 0.5831.. Val IoU: 0.4170\n",
      "Validation loss decreased (0.5831). Saving model...\n",
      "Epoch 4/25.. Train Loss: 0.4196.. Val Loss: 0.4053.. Val Dice: 0.6254.. Val IoU: 0.4613\n",
      "Validation loss decreased (0.6254). Saving model...\n",
      "Epoch 5/25.. Train Loss: 0.3871.. Val Loss: 0.3806.. Val Dice: 0.6298.. Val IoU: 0.4669\n",
      "Validation loss decreased (0.6298). Saving model...\n",
      "Epoch 6/25.. Train Loss: 0.3644.. Val Loss: 0.3805.. Val Dice: 0.6557.. Val IoU: 0.4929\n",
      "Validation loss decreased (0.6557). Saving model...\n",
      "Epoch 7/25.. Train Loss: 0.3398.. Val Loss: 0.3259.. Val Dice: 0.7042.. Val IoU: 0.5504\n",
      "Validation loss decreased (0.7042). Saving model...\n",
      "Epoch 8/25.. Train Loss: 0.3105.. Val Loss: 0.3199.. Val Dice: 0.6972.. Val IoU: 0.5439\n",
      "Validation loss decreased (0.6972). Saving model...\n",
      "Epoch 9/25.. Train Loss: 0.2910.. Val Loss: 0.3074.. Val Dice: 0.7202.. Val IoU: 0.5708\n",
      "Validation loss decreased (0.7202). Saving model...\n",
      "Epoch 10/25.. Train Loss: 0.2694.. Val Loss: 0.2953.. Val Dice: 0.7194.. Val IoU: 0.5701\n",
      "Validation loss decreased (0.7194). Saving model...\n",
      "Epoch 11/25.. Train Loss: 0.2567.. Val Loss: 0.2862.. Val Dice: 0.7288.. Val IoU: 0.5814\n",
      "Validation loss decreased (0.7288). Saving model...\n",
      "Epoch 12/25.. Train Loss: 0.2372.. Val Loss: 0.2856.. Val Dice: 0.7312.. Val IoU: 0.5834\n",
      "Validation loss decreased (0.7312). Saving model...\n",
      "Epoch 13/25.. Train Loss: 0.2360.. Val Loss: 0.2845.. Val Dice: 0.7466.. Val IoU: 0.6027\n",
      "Validation loss decreased (0.7466). Saving model...\n",
      "Epoch 14/25.. Train Loss: 0.2209.. Val Loss: 0.2440.. Val Dice: 0.7735.. Val IoU: 0.6381\n",
      "Validation loss decreased (0.7735). Saving model...\n",
      "Epoch 15/25.. Train Loss: 0.2078.. Val Loss: 0.2910.. Val Dice: 0.7098.. Val IoU: 0.5653\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 16/25.. Train Loss: 0.1981.. Val Loss: 0.2330.. Val Dice: 0.7790.. Val IoU: 0.6459\n",
      "Validation loss decreased (0.7790). Saving model...\n",
      "Epoch 17/25.. Train Loss: 0.1930.. Val Loss: 0.2697.. Val Dice: 0.7323.. Val IoU: 0.5912\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 18/25.. Train Loss: 0.1878.. Val Loss: 0.2789.. Val Dice: 0.7368.. Val IoU: 0.5908\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 19/25.. Train Loss: 0.1810.. Val Loss: 0.2653.. Val Dice: 0.7401.. Val IoU: 0.6012\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 20/25.. Train Loss: 0.1643.. Val Loss: 0.2557.. Val Dice: 0.7533.. Val IoU: 0.6176\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 21/25.. Train Loss: 0.1476.. Val Loss: 0.2099.. Val Dice: 0.8028.. Val IoU: 0.6784\n",
      "Validation loss decreased (0.8028). Saving model...\n",
      "Epoch 22/25.. Train Loss: 0.1285.. Val Loss: 0.2102.. Val Dice: 0.8034.. Val IoU: 0.6795\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 23/25.. Train Loss: 0.1235.. Val Loss: 0.2050.. Val Dice: 0.8111.. Val IoU: 0.6892\n",
      "Validation loss decreased (0.8111). Saving model...\n",
      "Epoch 24/25.. Train Loss: 0.1221.. Val Loss: 0.2043.. Val Dice: 0.8116.. Val IoU: 0.6903\n",
      "Validation loss decreased (0.8116). Saving model...\n",
      "Epoch 25/25.. Train Loss: 0.1190.. Val Loss: 0.2110.. Val Dice: 0.8037.. Val IoU: 0.6800\n",
      "EarlyStopping counter: 1 out of 5\n",
      "==================================================\n",
      "STARTING EXPERIMENT FOR AUGMENTATION: VFLIP\n",
      "==================================================\n",
      "Epoch 1/25.. Train Loss: 0.6070.. Val Loss: 0.5554.. Val Dice: 0.4971.. Val IoU: 0.3357\n",
      "Validation loss decreased (0.4971). Saving model...\n",
      "Epoch 2/25.. Train Loss: 0.5173.. Val Loss: 0.4994.. Val Dice: 0.5868.. Val IoU: 0.4197\n",
      "Validation loss decreased (0.5868). Saving model...\n",
      "Epoch 3/25.. Train Loss: 0.4731.. Val Loss: 0.4585.. Val Dice: 0.6134.. Val IoU: 0.4483\n",
      "Validation loss decreased (0.6134). Saving model...\n",
      "Epoch 4/25.. Train Loss: 0.4446.. Val Loss: 0.4691.. Val Dice: 0.6019.. Val IoU: 0.4352\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 5/25.. Train Loss: 0.4173.. Val Loss: 0.4128.. Val Dice: 0.6426.. Val IoU: 0.4772\n",
      "Validation loss decreased (0.6426). Saving model...\n",
      "Epoch 6/25.. Train Loss: 0.3932.. Val Loss: 0.3971.. Val Dice: 0.6353.. Val IoU: 0.4740\n",
      "Validation loss decreased (0.6353). Saving model...\n",
      "Epoch 7/25.. Train Loss: 0.3705.. Val Loss: 0.3623.. Val Dice: 0.6843.. Val IoU: 0.5290\n",
      "Validation loss decreased (0.6843). Saving model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 89\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Training loop for this experiment\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mNUM_EPOCHS):\n\u001b[0;32m     87\u001b[0m     \n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m     train_loss, train_dice, train_iou \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     val_loss, val_dice, val_iou \u001b[38;5;241m=\u001b[39m validate_epoch(\n\u001b[0;32m     95\u001b[0m         model, val_loader, criterion, device\n\u001b[0;32m     96\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Navn\\Documents\\Deep learning exam\\DL-MedicalImageSegmentation\\utils.py:110\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m    107\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Track metrics\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m total_dice \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dice_coefficient(outputs, masks)\n\u001b[0;32m    112\u001b[0m total_iou \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m iou_score(outputs, masks)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AUTOMATED EXPERIMENT LOOP - RUNS ALL AUGMENTATIONS\n",
    "# ============================================================================\n",
    "\n",
    "# Define all experiments to run\n",
    "experiments = [None, 'hflip', 'vflip', 'rotate', 'colorjitter', 'all']\n",
    "experiment_results = {}\n",
    "\n",
    "for AUGMENTATION_TYPE in experiments:\n",
    "    \n",
    "    # Determine save name\n",
    "    aug_name = AUGMENTATION_TYPE if AUGMENTATION_TYPE else 'baseline'\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(f\"STARTING EXPERIMENT FOR AUGMENTATION: {aug_name.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Re-create datasets for this experiment\n",
    "    train_dataset = KvasirDataset(\n",
    "        train_images, \n",
    "        train_masks, \n",
    "        target_size=config.TARGET_SIZE,\n",
    "        augmentation_type=AUGMENTATION_TYPE\n",
    "    )\n",
    "    \n",
    "    val_dataset = KvasirDataset(\n",
    "        val_images, \n",
    "        val_masks, \n",
    "        target_size=config.TARGET_SIZE,\n",
    "        augmentation_type=None\n",
    "    )\n",
    "    \n",
    "    # Re-create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize FRESH model for this experiment\n",
    "    model = UNet(in_channels=config.IN_CHANNELS, \n",
    "                 out_channels=config.OUT_CHANNELS).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = DiceBCELoss(weight_dice=0.5, weight_bce=0.5)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.LEARNING_RATE, weight_decay=1e-5)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='max',\n",
    "        factor=config.SCHEDULER_FACTOR,\n",
    "        patience=config.SCHEDULER_PATIENCE,\n",
    "        verbose=False  # Don't print LR changes\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_dice': [],\n",
    "        'train_iou': [],\n",
    "        'val_loss': [],\n",
    "        'val_dice': [],\n",
    "        'val_iou': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    # Early stopping\n",
    "    best_dice = 0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop for this experiment\n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_dice, train_iou = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_dice, val_iou = validate_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_dice)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_dice'].append(train_dice)\n",
    "        history['train_iou'].append(train_iou)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        history['val_iou'].append(val_iou)\n",
    "        history['lr'].append(current_lr)\n",
    "        \n",
    "        # Print single line format\n",
    "        print(f\"Epoch {epoch+1}/{config.NUM_EPOCHS}.. \"\n",
    "              f\"Train Loss: {train_loss:.4f}.. \"\n",
    "              f\"Val Loss: {val_loss:.4f}.. \"\n",
    "              f\"Val Dice: {val_dice:.4f}.. \"\n",
    "              f\"Val IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_dice = val_dice\n",
    "            best_iou = val_iou\n",
    "            patience_counter = 0\n",
    "            print(f\"Validation loss decreased ({val_dice:.4f}). Saving model...\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"EarlyStopping counter: {patience_counter} out of {config.EARLY_STOPPING_PATIENCE}\")\n",
    "        \n",
    "        # Check early stopping\n",
    "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"Early stopping triggered!\")\n",
    "            break\n",
    "        \n",
    "        experiment_results[aug_name] = {\n",
    "            'val_loss': float(best_val_loss),\n",
    "            'dice': float(best_dice),\n",
    "            'iou': float(best_iou)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eadf6f3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert dictionary to DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43mexperiment_results\u001b[49m, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m results_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAugmentation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m results_df \u001b[38;5;241m=\u001b[39m results_df\u001b[38;5;241m.\u001b[39msort_index()  \u001b[38;5;66;03m# sort alphabetically (optional)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'experiment_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert dictionary to DataFrame\n",
    "results_df = pd.DataFrame.from_dict(experiment_results, orient='index')\n",
    "results_df.index.name = 'Augmentation'\n",
    "results_df = results_df.sort_index()  # sort alphabetically (optional)\n",
    "\n",
    "print(\"\\n--- Final Augmentation Experiment Results ---\")\n",
    "print(results_df)\n",
    "\n",
    "# Optional: Plot the results\n",
    "results_df.plot(kind='bar', y=['dice', 'iou'],\n",
    "                title='Segmentation Metrics by Augmentation Type',\n",
    "                figsize=(10, 6))\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a32880c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Experiment Results ---\n",
      "Augmentation    val_loss     dice         iou         \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Display result COOKED\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n--- Final Experiment Results ---\")\n",
    "print(f\"{'Augmentation':<15} {'val_loss':<12} {'dice':<12} {'iou':<12}\")\n",
    "\n",
    "# Sort by dice score (highest first)\n",
    "sorted_results = sorted(all_results.items(), key=lambda x: x[1]['dice'], reverse=True)\n",
    "\n",
    "for aug_name, metrics in sorted_results:\n",
    "    print(f\"{aug_name:<15} {metrics['loss']:<12.6f} {metrics['dice']:<12.6f} {metrics['iou']:<12.6f}\")\n",
    "\n",
    "# Create comparison bar plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "augmentations = [item[0] for item in sorted_results]\n",
    "dice_scores = [item[1]['dice'] for item in sorted_results]\n",
    "iou_scores = [item[1]['iou'] for item in sorted_results]\n",
    "\n",
    "x = np.arange(len(augmentations))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, dice_scores, width, label='dice', color='#1f77b4')\n",
    "bars2 = ax.bar(x + width/2, iou_scores, width, label='iou', color='#ff7f0e')\n",
    "\n",
    "ax.set_xlabel('Augmentation', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Segmentation Metrics by Augmentation Type', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(augmentations)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, 0.85)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24c123",
   "metadata": {},
   "source": [
    "# Save results (aner ikke om dette trengs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cec34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history to CSV\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv('training_history_augmented.csv', index=False)\n",
    "print(\"History saved as 'training_history_augmented.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ALL RESULTS SAVED!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  1. best_model_augmented.pth          - Best model checkpoint\")\n",
    "print(\"  2. training_history_augmented.csv    - All metrics per epoch\")\n",
    "print(\"  3. training_results_augmented.png    - Training curves\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nTASK 2 COMPLETE!\")\n",
    "print(\"Your experiment: Training WITH augmentation (8 techniques)\")\n",
    "print(\"Focus of report: How augmentation improves generalization\")\n",
    "print(\"=\" * 70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
