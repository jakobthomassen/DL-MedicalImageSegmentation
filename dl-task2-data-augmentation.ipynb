{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fd52eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image                # For image loading\n",
    "import torch\n",
    "import torch.nn as nn                      # Core PyTorch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split  # Dataset tools\n",
    "from torchvision import transforms   # For preprocessing / augmentations\n",
    "import torchvision.transforms.functional as F  # For paired transforms\n",
    "import matplotlib.pyplot as plt       # Optional visualization\n",
    "import os, json, random, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a0a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87e225f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KvasirSegDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images = sorted(os.listdir(images_dir))\n",
    "        self.masks = sorted(os.listdir(masks_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# --- dataset & dataloaders ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = KvasirSegDataset(r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\",\n",
    "r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\", \n",
    "transform)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92b4a3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images and 1000 masks\n",
      "✅ Image/mask lists are aligned by basename.\n",
      "Split sizes -> train: 700, val: 300\n",
      "✅ Saved split file: C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\split_kvasirseg_seed1337.json\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Deterministic 70/30 split for Kvasir-SEG ---\n",
    "\n",
    "# 1) Set your folders (use raw string r\"\" or forward slashes to avoid \\U issues)\n",
    "IM_DIR = r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\images\"\n",
    "MS_DIR = r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\masks\"\n",
    "\n",
    "# 2) Basic checks\n",
    "assert os.path.isdir(IM_DIR), f\"Images folder not found: {IM_DIR}\"\n",
    "assert os.path.isdir(MS_DIR), f\"Masks folder not found: {MS_DIR}\"\n",
    "\n",
    "img_files = sorted([f for f in os.listdir(IM_DIR) if not f.startswith('.')])\n",
    "msk_files = sorted([f for f in os.listdir(MS_DIR) if not f.startswith('.')])\n",
    "\n",
    "print(f\"Found {len(img_files)} images and {len(msk_files)} masks\")\n",
    "\n",
    "# 3) (Optional but recommended) Check that file basenames match between folders\n",
    "#    Kvasir-SEG usually keeps identical names between images/ and masks/.\n",
    "def stem_no_ext(name: str) -> str:\n",
    "    return os.path.splitext(name)[0]\n",
    "\n",
    "img_stems = [stem_no_ext(f) for f in img_files]\n",
    "msk_stems = [stem_no_ext(f) for f in msk_files]\n",
    "\n",
    "if img_stems != msk_stems:\n",
    "    # Try a natural sort (e.g., \"2.png\" before \"10.png\")\n",
    "    def natural_key(s):\n",
    "        return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', s)]\n",
    "    img_files = sorted(img_files, key=natural_key)\n",
    "    msk_files = sorted(msk_files, key=natural_key)\n",
    "    img_stems = [stem_no_ext(f) for f in img_files]\n",
    "    msk_stems = [stem_no_ext(f) for f in msk_files]\n",
    "\n",
    "    if img_stems != msk_stems:\n",
    "        # last-resort: show a few mismatches to fix naming issues early\n",
    "        mismatches = [(i, a, b) for i, (a, b) in enumerate(zip(img_stems, msk_stems)) if a != b][:10]\n",
    "        raise RuntimeError(\n",
    "            \"Image/mask filename order mismatch. First mismatches:\\n\" +\n",
    "            \"\\n\".join([f\"{i}: {a}  vs  {b}\" for i, a, b in mismatches])\n",
    "        )\n",
    "\n",
    "print(\"✅ Image/mask lists are aligned by basename.\")\n",
    "\n",
    "# 4) Create deterministic indices (shuffle once with a fixed seed)\n",
    "N = len(img_files)\n",
    "assert N == len(msk_files), \"Different counts for images and masks.\"\n",
    "assert N >= 1, \"No files found.\"\n",
    "\n",
    "SEED = 1337\n",
    "rng = random.Random(SEED)\n",
    "indices = list(range(N))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "train_count = int(0.7 * N)  # 70%\n",
    "train_idx = indices[:train_count]\n",
    "val_idx   = indices[train_count:]\n",
    "\n",
    "print(f\"Split sizes -> train: {len(train_idx)}, val: {len(val_idx)}\")\n",
    "\n",
    "# 5) Save split to disk (JSON) next to the dataset (you can choose another location)\n",
    "split_out = Path(IM_DIR).parent / \"split_kvasirseg_seed1337.json\"\n",
    "with open(split_out, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"seed\": SEED, \"train_idx\": train_idx, \"val_idx\": val_idx}, f, indent=2)\n",
    "\n",
    "print(f\"✅ Saved split file: {split_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55db0c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 300\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\split_kvasirseg_seed1337.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sp = json.load(f)\n",
    "train_idx = sp[\"train_idx\"]\n",
    "val_idx   = sp[\"val_idx\"]\n",
    "\n",
    "print(len(train_idx), len(val_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca1956",
   "metadata": {},
   "source": [
    "# experiment design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de361e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 55\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "IM_DIR = r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\images\"\n",
    "MS_DIR = r\"C:\\Users\\olane\\OneDrive - Kristiania\\Git\\Exam DL\\Kvasir-SEG\\masks\"\n",
    "assert os.path.isdir(IM_DIR) and os.path.isdir(MS_DIR), \"Fix IM_DIR/MS_DIR paths.\"\n",
    "\n",
    "# deterministic 70/30 split (filenames only, assuming 1-1 matching sort order)\n",
    "all_imgs = sorted(os.listdir(IM_DIR))\n",
    "all_msks = sorted(os.listdir(MS_DIR))\n",
    "assert len(all_imgs)==len(all_msks)==1000\n",
    "\n",
    "# Option A: pure sort-based split (simple and reproducible)\n",
    "train_idx = list(range(700))\n",
    "val_idx   = list(range(700, 1000))\n",
    "\n",
    "# Option B (recommended): one-time deterministic shuffle & save\n",
    "# rnd = random.Random(SEED); idx = list(range(1000)); rnd.shuffle(idx)\n",
    "# train_idx, val_idx = idx[:700], idx[700:]\n",
    "# with open(\"split_kvasirseg_seed1337.json\",\"w\") as f: json.dump({\"train\":train_idx,\"val\":val_idx}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ca5f2",
   "metadata": {},
   "source": [
    "# Repro & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a56f503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class KvasirSegDataset(Dataset):\n",
    "    def __init__(self, im_dir, ms_dir, indices, policy=\"none\", size=(256,256)):\n",
    "        self.im_paths = [os.path.join(im_dir, f) for i,f in enumerate(sorted(os.listdir(im_dir))) if i in indices]\n",
    "        self.ms_paths = [os.path.join(ms_dir, f) for i,f in enumerate(sorted(os.listdir(ms_dir))) if i in indices]\n",
    "        self.policy = policy\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self): return len(self.im_paths)\n",
    "\n",
    "    def _geo_params(self):\n",
    "        # Shared random params for paired transforms\n",
    "        hflip = random.random() < 0.5\n",
    "        vflip = random.random() < 0.5\n",
    "        angle = random.uniform(-10, 10)\n",
    "        translate = (random.uniform(-0.05,0.05), random.uniform(-0.05,0.05)) # as fraction\n",
    "        scale = random.uniform(0.9, 1.1)\n",
    "        shear = random.uniform(-5, 5)\n",
    "        return hflip, vflip, angle, translate, scale, shear\n",
    "\n",
    "    def _apply_policy(self, img, msk):\n",
    "        w, h = img.size\n",
    "\n",
    "        if self.policy in (\"flip\",\"flip+rot\",\"geo+scale\",\"geo+color\",\"strong\"):\n",
    "            hflip, vflip, angle, translate, scale, shear = self._geo_params()\n",
    "\n",
    "            # flips\n",
    "            if self.policy in (\"flip\",\"flip+rot\",\"geo+scale\",\"geo+color\",\"strong\"):\n",
    "                if hflip:\n",
    "                    img = F.hflip(img); msk = F.hflip(msk)\n",
    "                if vflip:\n",
    "                    img = F.vflip(img); msk = F.vflip(msk)\n",
    "\n",
    "            # rotations / affine\n",
    "            if self.policy in (\"flip+rot\",\"geo+scale\",\"geo+color\",\"strong\"):\n",
    "                tx = int(translate[0]*w); ty = int(translate[1]*h)\n",
    "                img = F.affine(img, angle=angle, translate=(tx,ty), scale=1.0, shear=[shear,0], interpolation=F.InterpolationMode.BILINEAR)\n",
    "                msk = F.affine(msk, angle=angle, translate=(tx,ty), scale=1.0, shear=[shear,0], interpolation=F.InterpolationMode.NEAREST)\n",
    "\n",
    "            # random resize crop (scale jitter)\n",
    "            if self.policy in (\"geo+scale\",\"geo+color\",\"strong\"):\n",
    "                # simulate scale by resized crop: pick a crop <= original then resize back\n",
    "                scale_fac = random.uniform(0.85, 1.0)\n",
    "                cw, ch = int(w*scale_fac), int(h*scale_fac)\n",
    "                if cw>0 and ch>0:\n",
    "                    x = random.randint(0, max(0, w-cw))\n",
    "                    y = random.randint(0, max(0, h-ch))\n",
    "                    img = img.crop((x,y,x+cw,y+ch)).resize((w,h), Image.BILINEAR)\n",
    "                    msk = msk.crop((x,y,x+cw,y+ch)).resize((w,h), Image.NEAREST)\n",
    "\n",
    "            # image-only color jitter\n",
    "            if self.policy in (\"geo+color\",\"strong\"):\n",
    "                b = random.uniform(0.9,1.1)\n",
    "                c = random.uniform(0.9,1.1)\n",
    "                s = random.uniform(0.9,1.1)\n",
    "                img = F.adjust_brightness(img, b)\n",
    "                img = F.adjust_contrast(img,  c)\n",
    "                img = F.adjust_saturation(img, s)\n",
    "\n",
    "            # a bit stronger affine (acts like elastic-lite)\n",
    "            if self.policy == \"strong\":\n",
    "                angle2 = random.uniform(-15, 15)\n",
    "                shear2 = random.uniform(-8, 8)\n",
    "                img = F.affine(img, angle=angle2, translate=(0,0), scale=random.uniform(0.95,1.05),\n",
    "                               shear=[shear2,0], interpolation=F.InterpolationMode.BILINEAR)\n",
    "                msk = F.affine(msk, angle=angle2, translate=(0,0), scale=random.uniform(0.95,1.05),\n",
    "                               shear=[shear2,0], interpolation=F.InterpolationMode.NEAREST)\n",
    "\n",
    "        return img, msk\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.im_paths[idx]).convert(\"RGB\")\n",
    "        msk = Image.open(self.ms_paths[idx]).convert(\"L\")     # single-channel\n",
    "\n",
    "        if self.policy != \"none\":\n",
    "            img, msk = self._apply_policy(img, msk)\n",
    "\n",
    "        # final resize -> tensor\n",
    "        img = F.resize(img, self.size, interpolation=F.InterpolationMode.BILINEAR)\n",
    "        msk = F.resize(msk, self.size, interpolation=F.InterpolationMode.NEAREST)\n",
    "        img = F.to_tensor(img)                     # [3,H,W], 0..1\n",
    "        msk = (F.to_tensor(msk) > 0.5).float()     # [1,H,W] binary\n",
    "        return img, msk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230da3e",
   "metadata": {},
   "source": [
    "# Dataset with paired transforms (same geometry for image & mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d1fb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_block(cin, cout):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(cin, cout, 3, padding=1), nn.BatchNorm2d(cout), nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(cout, cout, 3, padding=1), nn.BatchNorm2d(cout), nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=1, base=32):\n",
    "        super().__init__()\n",
    "        self.enc1 = conv_block(in_ch, base)\n",
    "        self.enc2 = conv_block(base, base*2)\n",
    "        self.enc3 = conv_block(base*2, base*4)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bott = conv_block(base*4, base*8)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(base*8, base*4, 2, 2)\n",
    "        self.dec3 = conv_block(base*8, base*4)\n",
    "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, 2)\n",
    "        self.dec2 = conv_block(base*4, base*2)\n",
    "        self.up1 = nn.ConvTranspose2d(base*2, base, 2, 2)\n",
    "        self.dec1 = conv_block(base*2, base)\n",
    "\n",
    "        self.out  = nn.Conv2d(base, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x); p1 = self.pool(e1)\n",
    "        e2 = self.enc2(p1); p2 = self.pool(e2)\n",
    "        e3 = self.enc3(p2); p3 = self.pool(e3)\n",
    "\n",
    "        b  = self.bott(p3)\n",
    "\n",
    "        d3 = self.up3(b); d3 = torch.cat([d3, e3], 1); d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3); d2 = torch.cat([d2, e2], 1); d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2); d1 = torch.cat([d1, e1], 1); d1 = self.dec1(d1)\n",
    "        return self.out(d1)                         # logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e7e40",
   "metadata": {},
   "source": [
    "# unet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "efa777f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_iou(pred_logits, target, thr=0.5, eps=1e-7):\n",
    "    pred = (torch.sigmoid(pred_logits) > thr).float()\n",
    "    inter = (pred*target).sum(dim=(1,2,3))\n",
    "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "    dice = (2*inter + eps) / (union + eps)\n",
    "\n",
    "    # IoU: |A ∩ B| / |A ∪ B|\n",
    "    union_iou = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) - inter\n",
    "    iou = (inter + eps) / (union_iou + eps)\n",
    "    return dice.mean().item(), iou.mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    dices, ious = [], []\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        d,i = dice_iou(logits, y)\n",
    "        dices.append(d); ious.append(i)\n",
    "    return float(np.mean(dices)), float(np.mean(ious))\n",
    "\n",
    "def train_one_policy(policy_name, epochs=15, batch=8, lr=1e-3, size=(256,256), device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_ds = KvasirSegDataset(IM_DIR, MS_DIR, train_idx, policy=policy_name, size=size)\n",
    "    val_ds   = KvasirSegDataset(IM_DIR, MS_DIR, val_idx,   policy=\"none\",     size=size)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best = {\"val_dice\": -1, \"val_iou\": -1, \"epoch\": -1}\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        val_dice, val_iou = evaluate(model, val_loader, device)\n",
    "        if val_dice > best[\"val_dice\"]:\n",
    "            best = {\"val_dice\": val_dice, \"val_iou\": val_iou, \"epoch\": ep}\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a509b013",
   "metadata": {},
   "source": [
    "# Metrics (Dice, IoU) & training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "543bc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_iou(pred_logits, target, thr=0.5, eps=1e-7):\n",
    "    pred = (torch.sigmoid(pred_logits) > thr).float()\n",
    "    inter = (pred*target).sum(dim=(1,2,3))\n",
    "    union = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))\n",
    "    dice = (2*inter + eps) / (union + eps)\n",
    "\n",
    "    # IoU: |A ∩ B| / |A ∪ B|\n",
    "    union_iou = pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) - inter\n",
    "    iou = (inter + eps) / (union_iou + eps)\n",
    "    return dice.mean().item(), iou.mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    dices, ious = [], []\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        d,i = dice_iou(logits, y)\n",
    "        dices.append(d); ious.append(i)\n",
    "    return float(np.mean(dices)), float(np.mean(ious))\n",
    "\n",
    "def train_one_policy(policy_name, epochs=15, batch=8, lr=1e-3, size=(256,256), device=None):\n",
    "    device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_ds = KvasirSegDataset(IM_DIR, MS_DIR, train_idx, policy=policy_name, size=size)\n",
    "    val_ds   = KvasirSegDataset(IM_DIR, MS_DIR, val_idx,   policy=\"none\",     size=size)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=0)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best = {\"val_dice\": -1, \"val_iou\": -1, \"epoch\": -1}\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        val_dice, val_iou = evaluate(model, val_loader, device)\n",
    "        if val_dice > best[\"val_dice\"]:\n",
    "            best = {\"val_dice\": val_dice, \"val_iou\": val_iou, \"epoch\": ep}\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9bb9a",
   "metadata": {},
   "source": [
    "#  Run the ablation & log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efcb714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training policy: none ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m policies:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Training policy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     best = \u001b[43mtrain_one_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     best[\u001b[33m\"\u001b[39m\u001b[33mpolicy\u001b[39m\u001b[33m\"\u001b[39m] = p\n\u001b[32m      8\u001b[39m     results.append(best)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mtrain_one_policy\u001b[39m\u001b[34m(policy_name, epochs, batch, lr, size, device)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m):\n\u001b[32m     38\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mKvasirSegDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     78\u001b[39m img = F.resize(img, \u001b[38;5;28mself\u001b[39m.size, interpolation=F.InterpolationMode.BILINEAR)\n\u001b[32m     79\u001b[39m msk = F.resize(msk, \u001b[38;5;28mself\u001b[39m.size, interpolation=F.InterpolationMode.NEAREST)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m img = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m                     \u001b[38;5;66;03m# [3,H,W], 0..1\u001b[39;00m\n\u001b[32m     81\u001b[39m msk = (F.to_tensor(msk) > \u001b[32m0.5\u001b[39m).float()     \u001b[38;5;66;03m# [1,H,W] binary\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m img, msk\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\olane\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[32m    167\u001b[39m mode_to_nptype = {\u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m\"\u001b[39m: np.int32, \u001b[33m\"\u001b[39m\u001b[33mI;16\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.byteorder == \u001b[33m\"\u001b[39m\u001b[33mlittle\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mI;16B\u001b[39m\u001b[33m\"\u001b[39m: np.int16, \u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m: np.float32}\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m img = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pic.mode == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    171\u001b[39m     img = \u001b[32m255\u001b[39m * img\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "policies = [\"none\", \"flip\", \"flip+rot\", \"geo+scale\", \"geo+color\", \"strong\"]\n",
    "results = []\n",
    "\n",
    "for p in policies:\n",
    "    print(f\"\\n=== Training policy: {p} ===\")\n",
    "    best = train_one_policy(p, epochs=15, batch=8, lr=1e-3, size=(256,256))\n",
    "    best[\"policy\"] = p\n",
    "    results.append(best)\n",
    "\n",
    "# Pretty print table\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68712cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
